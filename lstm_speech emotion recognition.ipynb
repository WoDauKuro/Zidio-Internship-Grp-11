{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model with Checkpoints\n",
    "\n",
    "## Introduction\n",
    "This notebook demonstrates how to build an LSTM (Long Short-Term Memory) model for emotion recognition from speech. We will load audio data, preprocess it, and train an LSTM model while saving checkpoints for the best performing model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset from kaggle\n",
    "!kaggle datasets download -d ejlok1/toronto-emotional-speech-set-tess\n",
    "\n",
    "# Unzip downloaded dataset\n",
    "!unzip toronto-emotional-speech-set-tess.zip\n",
    "\n",
    "# Import necessary libraries\n",
    "import numpy as np  # For numerical operations\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import os  # For interacting with the operating system\n",
    "import seaborn as sns  # For data visualization\n",
    "import matplotlib.pyplot as plt  # For plotting graphs\n",
    "import librosa  # For audio processing\n",
    "import librosa.display  # For displaying audio signals\n",
    "from IPython.display import Audio  # For audio playback in the notebook\n",
    "import warnings  # To manage warning messages\n",
    "warnings.filterwarnings('ignore')  # Ignore warnings for cleaner output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store file paths and labels\n",
    "paths = []\n",
    "labels = []\n",
    "\n",
    "# Traverse the dataset directory to load audio files and their respective labels\n",
    "for dirname, _, filenames in os.walk('/content/tess toronto emotional speech set data'):\n",
    "    for filename in filenames:\n",
    "        paths.append(os.path.join(dirname, filename))  # Store the full path of the audio file\n",
    "        label = filename.split('_')[-1].split('.')[0].lower()  # Extract the label from the filename\n",
    "        labels.append(label)  # Store the label\n",
    "    if len(paths) == 2800:  # Break if we have loaded all files\n",
    "        break\n",
    "\n",
    "print('Dataset is Loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "- We use `os.walk` to traverse the directory containing the audio files.\n",
    "- Each audio file's path and label are extracted and stored in lists.\n",
    "- The dataset consists of 2800 audio files, categorized by emotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of loaded audio files\n",
    "len(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview of Loaded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 paths and their corresponding labels\n",
    "print(paths[:5])\n",
    "print(labels[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the paths and labels\n",
    "df = pd.DataFrame()\n",
    "df['speech'] = paths\n",
    "df['label'] = labels\n",
    "df.head()  # Display the first few rows of the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of labels\n",
    "label_counts = df['label'].value_counts()\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of emotions\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=df, x='label')\n",
    "plt.title('Distribution of Emotions')\n",
    "plt.xlabel('Emotion')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the waveform of an audio signal\n",
    "def waveplot(data, sr, emotion):\n",
    "    # Create a new figure with specified size\n",
    "    plt.figure(figsize=[10, 4])\n",
    "    # Set the title of the plot to the given emotion\n",
    "    plt.title(emotion, size=20)\n",
    "    # Display the waveform using librosa's waveshow function\n",
    "    librosa.display.waveshow(data, sr=sr)\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Function to plot the spectrogram of an audio signal\n",
    "def spectogram(data, sr, emotion):\n",
    "    # Compute the Short-Time Fourier Transform (STFT) of the audio data\n",
    "    x = librosa.stft(data)\n",
    "    # Convert the amplitude of the STFT to decibels\n",
    "    xdb = librosa.amplitude_to_db(abs(x))\n",
    "    # Create a new figure with specified size\n",
    "    plt.figure(figsize=(11, 4))\n",
    "    # Set the title of the plot to the given emotion\n",
    "    plt.title(emotion, size=20)\n",
    "    # Display the spectrogram using librosa's specshow function\n",
    "    librosa.display.specshow(xdb, sr=sr, x_axis='time', y_axis='hz')\n",
    "    # Add a color bar to indicate the scale of the spectrogram\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first few rows of the DataFrame to check the loaded data\n",
    "print(df.head())\n",
    "\n",
    "# Print the unique emotion labels present in the DataFrame\n",
    "print(df['label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the unique audio file paths in the DataFrame\n",
    "df['speech'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing `waveplot` and `spectogram` functions created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a specific emotion for visualization\n",
    "emotion = 'fear'\n",
    "\n",
    "# Extract the path of the first audio file associated with the specified emotion\n",
    "path = np.array(df['speech'][df['label'] == emotion])[0]\n",
    "\n",
    "# Load the audio file using librosa\n",
    "data, sampling_rate = librosa.load(path)\n",
    "\n",
    "# Call the waveplot function to visualize the audio waveform\n",
    "waveplot(data, sampling_rate, emotion)\n",
    "\n",
    "# Call the spectogram function to visualize the spectrogram of the audio\n",
    "spectogram(data, sampling_rate, emotion)\n",
    "\n",
    "# Play the audio file in the notebook\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Test the code above on other emotions***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features from audio files\n",
    "def extract_features(file_path):\n",
    "    audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast')  # Load audio file\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)  # Extract MFCC features\n",
    "    return np.mean(mfccs.T, axis=0)  # Return mean of MFCCs across time\n",
    "\n",
    "# Extract features for all audio files\n",
    "features = np.array([extract_features(path) for path in paths])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "- The `extract_features` function processes an audio file by loading it, extracting its MFCC features, and returning the mean MFCCs across time.\n",
    "- The second part of the code extracts these features for all audio files in the list `paths` and stores them in a NumPy array `features`, where each row corresponds to the feature vector for one audio file.\n",
    "\n",
    "### Note:\n",
    "- **MFCC (Mel Frequency Cepstral Coefficients)** are extracted as they are commonly used features for audio classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DataFrame to a format suitable for LSTM\n",
    "X = features  # Features\n",
    "y = pd.get_dummies(df['label']).values  # One-hot encode labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "- The dataset is split into training (80%) and testing (20%) sets to evaluate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LSTM Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X_train.shape[1], 1), return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))  # Output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "- The model is compiled with the categorical crossentropy loss function, suitable for multi-class classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training with Checkpoints\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define a callback to save the best model\n",
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, batch_size=32, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "- The model is trained, and checkpoints are saved for the best validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Model\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this notebook, we built an LSTM model to classify emotions from speech data. We demonstrated data loading, feature extraction, model training, and evaluation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
